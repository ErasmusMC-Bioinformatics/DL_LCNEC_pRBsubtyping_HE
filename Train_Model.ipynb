{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7c5d3c-b568-47dc-8876-e6fc08e17c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n@author: Teodora Trandafir \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "@author: Teodora Trandafir \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8e8133-cf0d-4970-bac3-50df2d1d3ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Update '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Update \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493dbc81-5a53-4a0c-be0e-09ea3243dabb",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f6652bd-a2d2-4c15-bd69-25ed03bf9cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import six\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import glob \n",
    "import sys\n",
    "import shutil\n",
    "from skimage import io\n",
    "from scipy import misc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.models import model_from_json, Sequential\n",
    "from tensorflow.keras.applications import InceptionResNetV2, ResNet50, EfficientNetV2B0, MobileNetV2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Lambda, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.activations import softmax, sigmoid\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, History, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator, ImageDataGenerator\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02065913-dffa-4f6d-8be4-0e773ca66df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 14:17:10.997572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.017103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.017204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices('GPU')\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50ad8e1-5675-4ab4-be4c-8d47b07c641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 31 14:17:11 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.67                 Driver Version: 550.67         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   35C    P5             59W /  420W |    5692MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1175      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A      5083    C+G   ...libexec/gnome-remote-desktop-daemon        258MiB |\n",
      "|    0   N/A  N/A   1218572      C   ...ra/anaconda3/envs/DL_img/bin/python       5412MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43cc43-b6dd-4b69-9248-e24a6bed46f5",
   "metadata": {},
   "source": [
    "#### Session settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29eb3c6-88ca-48f1-921f-a9c10bd8dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 14:17:11.190646: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 14:17:11.193394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.194026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.194487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.498121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.498276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.498371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.498448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16614 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0e7fb-1379-4778-b7c6-178e8c7d425f",
   "metadata": {},
   "source": [
    "#### Architecture settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4908a85f-6193-47d6-a1f7-97aa6dfd0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(figures_path, History, Exp, N_EPOCHS, foldN, runN):\n",
    "    if not os.path.exists('{}/{}'.format(figures_path, Exp)):\n",
    "        os.makedirs('{}/{}'.format(figures_path, Exp))\n",
    "    #plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    # Create two subplots and unpack the output array immediately\n",
    "    f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=False)\n",
    "    \n",
    "    ax1.plot(History.history[\"loss\"], label=\"train_loss\")\n",
    "    ax1.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "    ax1.set_title('Loss fold{} of run{}'.format(foldN, runN))\n",
    "    ax1.set_ylabel('Loss')\n",
    "    \n",
    "    ax2.plot(History.history[\"Accuracy\"], label=\"train_acc\")\n",
    "    ax2.plot(History.history[\"val_Accuracy\"], label=\"val_acc\")\n",
    "    ax2.set_title('Accuracy fold{} of run{}'.format(foldN, runN))\n",
    "    ax2.set_ylim(0,1)\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlim(0, N_EPOCHS)\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    \n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('{}/{}/Performance_fold{}{}.png'.format(figures_path, Exp, foldN, runN))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd73985-d7db-4a5f-9ea8-33c4ec0d2ec9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Work directory configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c08d73-9602-4720-8ec8-798cda9faf38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage/Projects/04_LCNEC/Principal\n",
      "/mnt/storage/Projects/04_LCNEC\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3cf76-eca7-46c5-9fa2-b70d35211acc",
   "metadata": {},
   "source": [
    "#### Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016b10f1-701b-4be2-a64b-13e8533421b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = os.getcwd()\n",
    "\n",
    "root_path = project_path + os.sep + 'Principal'\n",
    "data_path = project_path + os.sep + 'LCNEC_128_Consensus'\n",
    "folds_path = project_path + os.sep + 'LCNEC_128_Consensus_4folds'\n",
    "save_path = project_path + os.sep + 'augument'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881a7b89-6acf-4c89-8451-73d1502b4d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LCNEC_128_ultimate.zip',\n",
       " 'Experiments',\n",
       " 'Data_Archive_IHC',\n",
       " 'LCNEC_128_Consensus_V11_2nd_4folds',\n",
       " 'Test_LCNEC_128_Consensus_Biopsies',\n",
       " '.ipynb_checkpoints',\n",
       " 'LCNEC_128_Consensus_V11',\n",
       " 'SCC_masks_20x_128.zip',\n",
       " 'Preprocessing',\n",
       " 'Previous_attempts',\n",
       " 'Preprocessing_with_masks',\n",
       " 'Principal',\n",
       " 'Experiments_V1',\n",
       " 'Test_SCC_128',\n",
       " 'Experiments_V3_V4_V5',\n",
       " 'LCNEC_128_Consensus_V11_Test_2',\n",
       " 'Test_LCNEC_128_Consensus_Biopsies_2',\n",
       " 'LCNEC_128_Consensus_All',\n",
       " 'LCNEC_128_Consensus_V11_Test',\n",
       " 'Preprocessing_with_masks_2',\n",
       " 'LCNEC_128_Consensus_V11_4folds',\n",
       " 'Data_groups_timeline',\n",
       " 'Previous_attempts_V6-V13',\n",
       " 'Data_annotated_backup',\n",
       " 'Experiments_V6-V13',\n",
       " 'Experiments_V2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f812d0-a5ca-4bba-b292-5b81a2553768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seed to make training deterministic.\n",
    "SEED = 3\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06322320-34c7-4c18-8404-56dc3189835b",
   "metadata": {},
   "source": [
    "#### Input configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c83091-7fdb-465f-841c-b80544b4cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0']\n",
      "['T12-21028', 'T04-29612', 'T06-1349', 'T10-14994', 'T09-20292', 'H23-26063', 'T12-23176', 'T08-07800', 'T09-21310', 'T06-36014', 'T12-025063', 'H21-2643', 'T21-19855', 'T11-15693', 'T10-17506', 'H22-7537', 'T06-15230', 'H21-11135', 'H20-7575', 'T12-1775', 'T11-018111', 'T10-02288', 'H20-28675', 'T12-42525', 'T09-020872', 'T09-25062', 'T09-15595', 'T11-22093', 'T10-17366', 'T08-18308', 'H22-8273', 'T05-43721', 'T12-13076', 'T06-9449', 'T03-8591', 'H21-11779', 'T11-3650', 'T11-004315', 'T21-4052', 'T04-16007', 'T11-37240', 'T05-14627', 'H21-5375', 'H23-3028', 'T09-11669', 'T13-03603', 'T04-38007', 'T11-6577', 'T04-027776', 'T11-6270', 'T10-17446', 'T10-00479', 'T09-3755', 'T09-12936', 'T09-21445', 'T12-9652', 'T06-014185', 'T12-26370', 'T03-063718', 'T11-07048', 'T12-31705', 'T11-22476', 'T09-14771', 'T12-05753', 'T05-9503', 'T12-13417', 'T07-15708', 'T10-1165', 'T09-20053', 'H22-2962', 'T05-28359', 'T12-5564', 'T04-6242', 'T09-35169', 'T12-05670', 'T11-37218', 'T10-11697', 'T12-818', 'T08-060191', 'T10-43400', 'T07-066437', 'T05-8396', 'T09-15078', 'T12-22210', 'T11-24536', 'T06-12815', 'T10-34230', 'T06-032917', 'T10-11634', 'T07-015745', 'T09-24617', 'T11-065239', 'T07-2779', 'T08-20742', 'T05-05354', 'T12-31073', 'T11-02132', 'H21-20908', 'T09-3783', 'T11-22503']\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Set data info \"\"\"\n",
    "\n",
    "DISEASE = 'LCNEC_RB_consensus4'\n",
    "\n",
    "CLASSES = ([name for name in os.listdir(data_path)])\n",
    "print(CLASSES)\n",
    "N_CLASSES = len(CLASSES)\n",
    "class_weights = None\n",
    "\n",
    "GROUPS = list()\n",
    "for classi in CLASSES:\n",
    "    GROUPS.append([name for name in os.listdir(data_path+os.sep+classi)])\n",
    "GROUPS = GROUPS[0]+GROUPS[1]\n",
    "N_GROUPS = len(GROUPS) \n",
    "print(GROUPS)\n",
    "print(N_GROUPS)\n",
    "\n",
    "\"\"\" Set experiments repeats \"\"\"\n",
    "N_FOLDS = 4\n",
    "N_RUNS = 1\n",
    "\n",
    "\"\"\" Set model parameters \"\"\"\n",
    "MODEL_ARCH = 'teonet_u2'\n",
    "LOSS_FUNC = 'BBCE'\n",
    "N_EPOCHS = 50\n",
    "PATIENCE = 20\n",
    "PATCH_SIZE =128\n",
    "DOWNSIZING_FACTOR = 1 # 1 for original image size\n",
    "PATCH_SIZE = int(PATCH_SIZE/DOWNSIZING_FACTOR) # both height and width\n",
    "BATCH_SIZE = 128 * DOWNSIZING_FACTOR * DOWNSIZING_FACTOR\n",
    "LR = 1e-4\n",
    "\"\"\" Set randomization parameters \"\"\"\n",
    "SHUFFLE = True\n",
    "\n",
    "\"\"\" Set required metrics evaluation \"\"\"\n",
    "METRICS = [\"Accuracy\"]\n",
    "#METRICS = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "\n",
    "\"\"\" Set annalysed fold \"\"\"\n",
    "foldN = 1\n",
    "runN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c45a61e6-03fc-41d3-917a-197d418f8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set required functions \"\"\"\n",
    "\n",
    "OPTIMIZER = keras.optimizers.Adam(learning_rate=LR, beta_1=0.9, beta_2=0.999, epsilon=None, decay=LR*0.1, amsgrad=True, name='Adam')\n",
    "\n",
    "LOSS = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f1b40a-494a-48d4-b7da-09aefb12b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set experiment name \"\"\"\n",
    "\n",
    "Exp = DISEASE+'_'+MODEL_ARCH+'_'+LOSS_FUNC+'_'+str(N_CLASSES)+'_'+str(PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a970b9-26dd-47a7-be03-7b6100600fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Pretrained weights \"\"\"\n",
    "\n",
    "pretrained_weights = None\n",
    "print(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef902486-00f0-49a0-8413-b6e2d3a7a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Output locations\"\"\"\n",
    "\n",
    "history_path = '{}/Experiments/{}/history_data'.format(project_path, Exp)\n",
    "weights_path = '{}/Experiments/{}/weights_data'.format(project_path, Exp)\n",
    "figures_path = '{}/Experiments/{}/figures_data'.format(project_path, Exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ce28001-23bc-4842-a321-9965e2abe3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" Check initial numbers \"\"\"\n",
    "# for subdirs, dirs, files in os.walk(folds_path):\n",
    "#     print(subdirs, \"has \", len(os.listdir(subdirs)), \" elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64adef5f-9e3e-4bd1-96f8-767a855fd0b3",
   "metadata": {},
   "source": [
    "#### Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd0853b6-20b5-4836-8d81-ecf26f8fc5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image):\n",
    "    return np.rot90(image, np.random.choice([0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392b5ef-5b7a-4baf-bddf-77886fb3094f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad7393a3-0365-46b2-9c5a-03cd5aa0b601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Augmentation/preprocessing setup for training and validation data generator \"\"\"\n",
    "\n",
    "augmentation_arguments_train = dict(featurewise_center=False,\n",
    "                                    samplewise_center = False,\n",
    "                                    featurewise_std_normalization = False,\n",
    "                                    samplewise_std_normalization = False,\n",
    "                                    rotation_range = None,\n",
    "                                    brightness_range = None,\n",
    "                                    horizontal_flip = True,\n",
    "                                    vertical_flip = True,\n",
    "                                    rescale = 1./255.,\n",
    "                                    # fill_mode = \"constant\",\n",
    "                                    # cval = 255.0,\n",
    "                                    preprocessing_function = rotate_image) #tf.keras.applications.resnet_v2.preprocess_input)\n",
    "\n",
    "augmentation_arguments_valid = dict(featurewise_center = False,\n",
    "                                    samplewise_center = False,\n",
    "                                    featurewise_std_normalization = False,\n",
    "                                    samplewise_std_normalization = False,\n",
    "                                    rotation_range = None,\n",
    "                                    brightness_range = None,\n",
    "                                    horizontal_flip = False,\n",
    "                                    vertical_flip = False,\n",
    "                                    rescale = 1./255.,\n",
    "                                    # fill_mode = \"constant\",\n",
    "                                    # cval = 255.0,\n",
    "                                    preprocessing_function = None) #tf.keras.applications.resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60b5d1-65bf-4ca0-9d3f-ba1ca6616d99",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29c40352-b6ed-4e15-b09c-e9c8a087eef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20559 images belonging to 2 classes.\n",
      "Found 6935 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"-------------------- Data generator --------------------\"\"\" \n",
    "\n",
    "train_path = '{}/Fold{}{}/Train/'.format(folds_path, foldN, runN)\n",
    "valid_path = '{}/Fold{}{}/Validation/'.format(folds_path, foldN, runN)\n",
    "\n",
    "\n",
    "\"\"\"--------------------- Generate batches of tiles from train and validation set of this fold ---------------------\"\"\"\n",
    "train_datagen = ImageDataGenerator(**augmentation_arguments_train).flow_from_directory(directory = train_path, \n",
    "                                                                                        batch_size = BATCH_SIZE, \n",
    "                                                                                        target_size = (PATCH_SIZE,PATCH_SIZE),\n",
    "                                                                                        color_mode = \"rgb\",\n",
    "                                                                                        class_mode = \"binary\", \n",
    "                                                                                        #classes = CLASSES,\n",
    "                                                                                        seed = SEED,\n",
    "                                                                                        shuffle = True,\n",
    "                                                                                        #save_to_dir = save_path\n",
    "                                                                                      )\n",
    "\n",
    "valid_datagen = ImageDataGenerator(**augmentation_arguments_valid).flow_from_directory(directory = valid_path,\n",
    "                                                                                        batch_size = BATCH_SIZE, \n",
    "                                                                                        target_size = (PATCH_SIZE,PATCH_SIZE),\n",
    "                                                                                        color_mode= \"rgb\",\n",
    "                                                                                        class_mode = \"binary\", \n",
    "                                                                                        #classes = CLASSES,\n",
    "                                                                                        seed= SEED,\n",
    "                                                                                        shuffle = False)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f92cbf4-71af-402d-bc50-bb05e77c843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02b6add1-1d15-4edb-99dd-afb8808273f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_datagen.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ac276c7-1303-454a-98b1-f2046ce325d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20559\n",
      "6935\n"
     ]
    }
   ],
   "source": [
    "\"\"\"--------------------- Calculate number of tiles in train and validation set ---------------------\"\"\"    \n",
    "\n",
    "n_train_samples, n_validation_samples = 0, 0\n",
    "for classi in CLASSES:\n",
    "    for sample in os.listdir('{}/{}'.format(train_path, classi)):\n",
    "         n_train_samples += len(os.listdir('{}/{}/{}'.format(train_path, classi, sample)))\n",
    "    for sample in os.listdir('{}/{}'.format(valid_path, classi)):        \n",
    "        n_validation_samples += len(os.listdir('{}/{}/{}'.format(valid_path, classi, sample)))\n",
    "    \n",
    "print(n_train_samples)\n",
    "print(n_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "118c438a-685a-475d-a394-74fd609b3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------------------- Set model weigths location ---------------------\"\"\"\n",
    "\n",
    "if not os.path.exists('{}/Fold{}{}'.format(weights_path, foldN, runN)):\n",
    "    os.makedirs('{}/Fold{}{}'.format(weights_path, foldN, runN))\n",
    "model_weights = '{}/Fold{}{}/Weights_{}_{}{}_'.format(weights_path, foldN, runN, Exp, foldN, runN)\n",
    "model_weights = model_weights + '{epoch:02d}_{val_loss:.2f}.hdf5' \n",
    "csv_log = model_weights + '.csv' \n",
    "# if not os.path.exists(model_weights):\n",
    "#     with open(model_weights, 'w'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15a40c3a-6b65-4089-b050-9d76d8d95625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------------------- Set callbacks ---------------------\"\"\"\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(model_weights, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', save_freq = \"epoch\")\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=0, min_lr=1e-7)\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = PATIENCE, verbose = 1, mode = 'auto')\n",
    "cvs_logger = CSVLogger(csv_log, separator=',', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6576d547-c976-4556-9091-9dd8a7fa1ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 124, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 120, 120, 32)      25632     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 120, 120, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 60, 60, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 58, 58, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 56, 56, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2359424   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,665,377\n",
      "Trainable params: 2,664,929\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 14:17:11.862787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.862976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.863056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.863164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.863241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-31 14:17:11.863296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16614 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"-------------------- Fit model --------------------\"\"\"\n",
    "\n",
    "from model_u2 import *\n",
    "\n",
    "model = create_binary_classification_model(input_shape=(PATCH_SIZE, PATCH_SIZE, 3))\n",
    "\n",
    "model.compile(optimizer = OPTIMIZER, loss = LOSS, metrics = METRICS)\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90d137ea-0b8b-42bd-9060-48003c54d623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9108994240141781, 1: 1.1084213931421179}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"-------------------- Calculate the weights for each class so that we can balance the data --------------------\"\"\"\n",
    "\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(train_datagen.classes), y = train_datagen.classes)\n",
    "class_weights = dict(zip(np.unique(train_datagen.classes), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6348cdac-e72e-4a14-885f-569283a7c63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 14:17:12.974167: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n",
      "2024-07-31 14:17:14.313309: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 3.5115 - Accuracy: 0.6868\n",
      "Epoch 1: val_loss improved from inf to 3.55007, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_01_3.55.hdf5\n",
      "160/160 [==============================] - 13s 65ms/step - loss: 3.5115 - Accuracy: 0.6868 - val_loss: 3.5501 - val_Accuracy: 0.5618\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 3.1686 - Accuracy: 0.7349\n",
      "Epoch 2: val_loss improved from 3.55007 to 3.34093, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_02_3.34.hdf5\n",
      "160/160 [==============================] - 10s 61ms/step - loss: 3.1686 - Accuracy: 0.7349 - val_loss: 3.3409 - val_Accuracy: 0.6657\n",
      "Epoch 3/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 2.8752 - Accuracy: 0.7714\n",
      "Epoch 3: val_loss did not improve from 3.34093\n",
      "160/160 [==============================] - 10s 61ms/step - loss: 2.8743 - Accuracy: 0.7715 - val_loss: 3.7014 - val_Accuracy: 0.5253\n",
      "Epoch 4/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 2.6176 - Accuracy: 0.7952\n",
      "Epoch 4: val_loss did not improve from 3.34093\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 2.6169 - Accuracy: 0.7952 - val_loss: 4.2756 - val_Accuracy: 0.6156\n",
      "Epoch 5/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 2.3964 - Accuracy: 0.8105\n",
      "Epoch 5: val_loss did not improve from 3.34093\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 2.3958 - Accuracy: 0.8107 - val_loss: 4.4826 - val_Accuracy: 0.6188\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 2.1818 - Accuracy: 0.8427\n",
      "Epoch 6: val_loss improved from 3.34093 to 2.96885, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_06_2.97.hdf5\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 2.1818 - Accuracy: 0.8427 - val_loss: 2.9689 - val_Accuracy: 0.5692\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 2.0149 - Accuracy: 0.8546\n",
      "Epoch 7: val_loss improved from 2.96885 to 2.83914, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_07_2.84.hdf5\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 2.0149 - Accuracy: 0.8546 - val_loss: 2.8391 - val_Accuracy: 0.6372\n",
      "Epoch 8/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.8686 - Accuracy: 0.8657\n",
      "Epoch 8: val_loss did not improve from 2.83914\n",
      "160/160 [==============================] - 10s 62ms/step - loss: 1.8683 - Accuracy: 0.8656 - val_loss: 3.1485 - val_Accuracy: 0.5576\n",
      "Epoch 9/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.7465 - Accuracy: 0.8723\n",
      "Epoch 9: val_loss improved from 2.83914 to 2.73923, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_09_2.74.hdf5\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 1.7457 - Accuracy: 0.8725 - val_loss: 2.7392 - val_Accuracy: 0.5570\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 1.6291 - Accuracy: 0.8856\n",
      "Epoch 10: val_loss did not improve from 2.73923\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 1.6291 - Accuracy: 0.8856 - val_loss: 2.7527 - val_Accuracy: 0.5554\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 1.5398 - Accuracy: 0.8906\n",
      "Epoch 11: val_loss improved from 2.73923 to 2.31131, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_11_2.31.hdf5\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 1.5398 - Accuracy: 0.8906 - val_loss: 2.3113 - val_Accuracy: 0.6016\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 1.4463 - Accuracy: 0.9011\n",
      "Epoch 12: val_loss did not improve from 2.31131\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 1.4463 - Accuracy: 0.9011 - val_loss: 2.6801 - val_Accuracy: 0.6182\n",
      "Epoch 13/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.3818 - Accuracy: 0.9027\n",
      "Epoch 13: val_loss did not improve from 2.31131\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 1.3812 - Accuracy: 0.9029 - val_loss: 2.9414 - val_Accuracy: 0.6387\n",
      "Epoch 14/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.3119 - Accuracy: 0.9112\n",
      "Epoch 14: val_loss did not improve from 2.31131\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 1.3117 - Accuracy: 0.9113 - val_loss: 2.3752 - val_Accuracy: 0.5885\n",
      "Epoch 15/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.2603 - Accuracy: 0.9126\n",
      "Epoch 15: val_loss did not improve from 2.31131\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 1.2603 - Accuracy: 0.9127 - val_loss: 2.3619 - val_Accuracy: 0.5593\n",
      "Epoch 16/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.2146 - Accuracy: 0.9132\n",
      "Epoch 16: val_loss improved from 2.31131 to 2.18148, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_16_2.18.hdf5\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 1.2143 - Accuracy: 0.9133 - val_loss: 2.1815 - val_Accuracy: 0.5897\n",
      "Epoch 17/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.1578 - Accuracy: 0.9207\n",
      "Epoch 17: val_loss improved from 2.18148 to 2.05352, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_17_2.05.hdf5\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 1.1574 - Accuracy: 0.9209 - val_loss: 2.0535 - val_Accuracy: 0.6450\n",
      "Epoch 18/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.1190 - Accuracy: 0.9236\n",
      "Epoch 18: val_loss improved from 2.05352 to 1.95467, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_18_1.95.hdf5\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 1.1188 - Accuracy: 0.9236 - val_loss: 1.9547 - val_Accuracy: 0.6283\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 1.0831 - Accuracy: 0.9239\n",
      "Epoch 19: val_loss did not improve from 1.95467\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 1.0831 - Accuracy: 0.9239 - val_loss: 2.2659 - val_Accuracy: 0.5888\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 1.0425 - Accuracy: 0.9318\n",
      "Epoch 20: val_loss did not improve from 1.95467\n",
      "160/160 [==============================] - 10s 62ms/step - loss: 1.0425 - Accuracy: 0.9318 - val_loss: 2.1175 - val_Accuracy: 0.6123\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 1.0167 - Accuracy: 0.9314\n",
      "Epoch 21: val_loss did not improve from 1.95467\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 1.0167 - Accuracy: 0.9314 - val_loss: 2.6093 - val_Accuracy: 0.5365\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.9792 - Accuracy: 0.9366\n",
      "Epoch 22: val_loss improved from 1.95467 to 1.79679, saving model to /mnt/storage/Projects/04_LCNEC/Experiments/LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128/weights_data/Fold41/Weights_LCNEC_RB_consensus4_V11_teonet_u3_BBCE_2_128_41_22_1.80.hdf5\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.9792 - Accuracy: 0.9366 - val_loss: 1.7968 - val_Accuracy: 0.6004\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.9543 - Accuracy: 0.9370\n",
      "Epoch 23: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 61ms/step - loss: 0.9543 - Accuracy: 0.9370 - val_loss: 2.6160 - val_Accuracy: 0.6231\n",
      "Epoch 24/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.9313 - Accuracy: 0.9390\n",
      "Epoch 24: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.9309 - Accuracy: 0.9392 - val_loss: 2.9121 - val_Accuracy: 0.5781\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.9089 - Accuracy: 0.9402\n",
      "Epoch 25: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 61ms/step - loss: 0.9089 - Accuracy: 0.9402 - val_loss: 2.3508 - val_Accuracy: 0.6194\n",
      "Epoch 26/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.8892 - Accuracy: 0.9401\n",
      "Epoch 26: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.8890 - Accuracy: 0.9402 - val_loss: 1.9919 - val_Accuracy: 0.5663\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.8655 - Accuracy: 0.9449\n",
      "Epoch 27: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.8655 - Accuracy: 0.9449 - val_loss: 2.0254 - val_Accuracy: 0.5437\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.8516 - Accuracy: 0.9444\n",
      "Epoch 28: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.8516 - Accuracy: 0.9444 - val_loss: 2.4855 - val_Accuracy: 0.5480\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.8281 - Accuracy: 0.9475\n",
      "Epoch 29: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.8281 - Accuracy: 0.9475 - val_loss: 1.8446 - val_Accuracy: 0.5891\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.8070 - Accuracy: 0.9499\n",
      "Epoch 30: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 62ms/step - loss: 0.8070 - Accuracy: 0.9499 - val_loss: 2.0110 - val_Accuracy: 0.5858\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.7885 - Accuracy: 0.9499\n",
      "Epoch 31: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.7885 - Accuracy: 0.9499 - val_loss: 2.4627 - val_Accuracy: 0.5838\n",
      "Epoch 32/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.7789 - Accuracy: 0.9511\n",
      "Epoch 32: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.7786 - Accuracy: 0.9512 - val_loss: 2.3987 - val_Accuracy: 0.5437\n",
      "Epoch 33/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.7624 - Accuracy: 0.9525\n",
      "Epoch 33: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.7621 - Accuracy: 0.9527 - val_loss: 2.2170 - val_Accuracy: 0.5367\n",
      "Epoch 34/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.7561 - Accuracy: 0.9516\n",
      "Epoch 34: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.7561 - Accuracy: 0.9517 - val_loss: 3.1779 - val_Accuracy: 0.6050\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.7351 - Accuracy: 0.9542\n",
      "Epoch 35: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.7351 - Accuracy: 0.9542 - val_loss: 2.3459 - val_Accuracy: 0.5624\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.7274 - Accuracy: 0.9533\n",
      "Epoch 36: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 60ms/step - loss: 0.7274 - Accuracy: 0.9533 - val_loss: 2.1036 - val_Accuracy: 0.5408\n",
      "Epoch 37/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.7145 - Accuracy: 0.9558\n",
      "Epoch 37: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 59ms/step - loss: 0.7144 - Accuracy: 0.9557 - val_loss: 2.6926 - val_Accuracy: 0.5894\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.7038 - Accuracy: 0.9566\n",
      "Epoch 38: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 61ms/step - loss: 0.7038 - Accuracy: 0.9566 - val_loss: 2.1098 - val_Accuracy: 0.6007\n",
      "Epoch 39/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6948 - Accuracy: 0.9571\n",
      "Epoch 39: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 10s 61ms/step - loss: 0.6950 - Accuracy: 0.9571 - val_loss: 1.9086 - val_Accuracy: 0.5829\n",
      "Epoch 40/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6880 - Accuracy: 0.9570\n",
      "Epoch 40: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 9s 58ms/step - loss: 0.6881 - Accuracy: 0.9570 - val_loss: 2.0357 - val_Accuracy: 0.6000\n",
      "Epoch 41/50\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6788 - Accuracy: 0.9573\n",
      "Epoch 41: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.6789 - Accuracy: 0.9572 - val_loss: 1.9228 - val_Accuracy: 0.5593\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.6664 - Accuracy: 0.9602\n",
      "Epoch 42: val_loss did not improve from 1.79679\n",
      "160/160 [==============================] - 9s 59ms/step - loss: 0.6664 - Accuracy: 0.9602 - val_loss: 2.7803 - val_Accuracy: 0.5514\n",
      "Epoch 42: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\"-------------------- Train model --------------------\"\"\"\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(train_datagen,          \n",
    "                    steps_per_epoch = math.floor(n_train_samples/BATCH_SIZE),\n",
    "                    epochs = N_EPOCHS,\n",
    "                    class_weight= class_weights,\n",
    "                    validation_data = valid_datagen,\n",
    "                    shuffle = True,\n",
    "                    callbacks = [model_checkpoint, earlystop, cvs_logger],#reduce_lr\n",
    "                    validation_steps = math.floor(n_validation_samples/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef4b6cce-aca9-476e-8045-3b223675bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"-------------------- Save the weights in the current directory --------------------\"\"\"  \n",
    "\n",
    "#for i, w in enumerate(model.weights): print(i, w.name) \n",
    "model.save_weights(model_weights)\n",
    "print(\"Weights saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b94492d-6239-434b-94c8-3b3770ae4a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"-------------------- Plot the model history --------------------\"\"\"\n",
    "\n",
    "plot_performance(figures_path, history, Exp, N_EPOCHS, foldN, runN)\n",
    "K.clear_session()\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de1f9406-b557-4830-8065-8e03caf94be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Clear session cashe\"\"\"\n",
    "\n",
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c56bcb60-7451-45bb-bbbb-3390e3c810ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!reboot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362477de-f0da-4e96-8e4e-60e3deba591a",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_img",
   "language": "python",
   "name": "dl_img"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
